{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b4ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def fine_grained_sentimental_analysis(content):   \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")   \n",
    "    tokens = tokenizer.encode(content, return_tensors='pt', truncation=True, padding=True)\n",
    "    result = model(tokens)\n",
    "    result.logits\n",
    "    sentiment_score = int(torch.argmax(result.logits))+1\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2966600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import contextlib\n",
    "import re\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    with contextlib.suppress(Exception):\n",
    "        # remove special characters except full stop and apostrophe\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.]', '', text)\n",
    "\n",
    "        # text = text.lower()  # convert text to lowercase\n",
    "        text = text.strip()  # remove leading and trailing whitespaces\n",
    "        text = text.encode('ascii', 'ignore').decode('ascii')  # remove non-ascii characters\n",
    "\n",
    "        # split text into words without messing up the punctuation\n",
    "        text = re.findall(r\"[\\w']+|[.,!?;]\", text)\n",
    "    \n",
    "        text= ' '.join(text)\n",
    "        return text.replace(' .', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e13f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_title'] = df['title'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66df186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c29b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['preprocessed_title'].apply(fine_grained_sentimental_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05573019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5543efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dfe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['score'].map({\n",
    "    5: \"Very Positive\",\n",
    "    4: \"Positive\",\n",
    "    3: \"Neutral\",\n",
    "    2: \"Negative\",\n",
    "    1: \"Very Negative\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51ff33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['preprocessed_content'] = df_new['content'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "378e5fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>content</th>\n",
       "      <th>preprocessed_title</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>preprocessed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': 'reuters', 'name': 'Reuters'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IBM reports highest annual revenue growth in a...</td>\n",
       "      <td>IBM Corp &lt;a href=\"https://www.reuters.com/comp...</td>\n",
       "      <td>https://www.reuters.com/technology/ibm-reports...</td>\n",
       "      <td>https://www.reuters.com/resizer/FjOhONjPelMPMz...</td>\n",
       "      <td>2023-01-25T21:12:00Z</td>\n",
       "      <td>Jan 25 (Reuters) - IBM Corp (IBM.N) on Wednesd...</td>\n",
       "      <td>IBM report high annual revenue growth decade r...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>Jan 25 Reuters IBM Corp IBM. N on Wednesday re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': 'business-insider', 'name': 'Business I...</td>\n",
       "      <td>insider@insider.com (Yanet Borrego)</td>\n",
       "      <td>I was a career coach on the side for years bef...</td>\n",
       "      <td>Yanet Borrego spent nine years as an engineer ...</td>\n",
       "      <td>https://www.businessinsider.com/quit-6-figure-...</td>\n",
       "      <td>https://i.insider.com/63c98aeceee94d001a78fbc5...</td>\n",
       "      <td>2023-01-23T18:55:16Z</td>\n",
       "      <td>I spent seven years at ExxonMobil and two year...</td>\n",
       "      <td>career coach year quit 6 figure consulting job...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>I spent seven years at ExxonMobil and two year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 'business-insider', 'name': 'Business I...</td>\n",
       "      <td>amok@insider.com (Aaron Mok)</td>\n",
       "      <td>How people are making money on Canva and turni...</td>\n",
       "      <td>Workers are leaving their full-time jobs to st...</td>\n",
       "      <td>https://www.businessinsider.com/workers-leavin...</td>\n",
       "      <td>https://i.insider.com/63612637ade71a00193dc7db...</td>\n",
       "      <td>2023-01-28T14:08:25Z</td>\n",
       "      <td>After a tech startup fired 31-year-old Shruti ...</td>\n",
       "      <td>people make money Canva turn graphic design hu...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>After a tech startup fired 31yearold Shruti Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': None, 'name': 'VentureBeat'}</td>\n",
       "      <td>Dean Takahashi</td>\n",
       "      <td>Consumer and business interest in the metavers...</td>\n",
       "      <td>Consumers and businesses are getting more inte...</td>\n",
       "      <td>https://venturebeat.com/games/consumer-and-bus...</td>\n",
       "      <td>https://venturebeat.com/wp-content/uploads/202...</td>\n",
       "      <td>2023-01-04T13:00:00Z</td>\n",
       "      <td>Connect with gaming and metaverse leaders onli...</td>\n",
       "      <td>consumer business interest metaverse grow | ac...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>Connect with gaming and metaverse leaders onli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': None, 'name': 'VentureBeat'}</td>\n",
       "      <td>Michael Biltz, Accenture Labs, Marc Carrel-Bil...</td>\n",
       "      <td>Plan now for the internetâ€™s transformation b...</td>\n",
       "      <td>How Web3 and the metaverse will transform the ...</td>\n",
       "      <td>https://venturebeat.com/virtual/plan-now-for-t...</td>\n",
       "      <td>https://venturebeat.com/wp-content/uploads/202...</td>\n",
       "      <td>2023-01-29T16:20:00Z</td>\n",
       "      <td>Check out all the on-demand sessions from the ...</td>\n",
       "      <td>plan internetâ€ ™ s transformation metaverse Web3</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Check out all the ondemand sessions from the I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0               {'id': 'reuters', 'name': 'Reuters'}   \n",
       "1  {'id': 'business-insider', 'name': 'Business I...   \n",
       "2  {'id': 'business-insider', 'name': 'Business I...   \n",
       "3                {'id': None, 'name': 'VentureBeat'}   \n",
       "4                {'id': None, 'name': 'VentureBeat'}   \n",
       "\n",
       "                                              author  \\\n",
       "0                                                NaN   \n",
       "1                insider@insider.com (Yanet Borrego)   \n",
       "2                       amok@insider.com (Aaron Mok)   \n",
       "3                                     Dean Takahashi   \n",
       "4  Michael Biltz, Accenture Labs, Marc Carrel-Bil...   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM reports highest annual revenue growth in a...   \n",
       "1  I was a career coach on the side for years bef...   \n",
       "2  How people are making money on Canva and turni...   \n",
       "3  Consumer and business interest in the metavers...   \n",
       "4  Plan now for the internetâ€™s transformation b...   \n",
       "\n",
       "                                         description  \\\n",
       "0  IBM Corp <a href=\"https://www.reuters.com/comp...   \n",
       "1  Yanet Borrego spent nine years as an engineer ...   \n",
       "2  Workers are leaving their full-time jobs to st...   \n",
       "3  Consumers and businesses are getting more inte...   \n",
       "4  How Web3 and the metaverse will transform the ...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reuters.com/technology/ibm-reports...   \n",
       "1  https://www.businessinsider.com/quit-6-figure-...   \n",
       "2  https://www.businessinsider.com/workers-leavin...   \n",
       "3  https://venturebeat.com/games/consumer-and-bus...   \n",
       "4  https://venturebeat.com/virtual/plan-now-for-t...   \n",
       "\n",
       "                                          urlToImage           publishedAt  \\\n",
       "0  https://www.reuters.com/resizer/FjOhONjPelMPMz...  2023-01-25T21:12:00Z   \n",
       "1  https://i.insider.com/63c98aeceee94d001a78fbc5...  2023-01-23T18:55:16Z   \n",
       "2  https://i.insider.com/63612637ade71a00193dc7db...  2023-01-28T14:08:25Z   \n",
       "3  https://venturebeat.com/wp-content/uploads/202...  2023-01-04T13:00:00Z   \n",
       "4  https://venturebeat.com/wp-content/uploads/202...  2023-01-29T16:20:00Z   \n",
       "\n",
       "                                             content  \\\n",
       "0  Jan 25 (Reuters) - IBM Corp (IBM.N) on Wednesd...   \n",
       "1  I spent seven years at ExxonMobil and two year...   \n",
       "2  After a tech startup fired 31-year-old Shruti ...   \n",
       "3  Connect with gaming and metaverse leaders onli...   \n",
       "4  Check out all the on-demand sessions from the ...   \n",
       "\n",
       "                                  preprocessed_title  score      sentiment  \\\n",
       "0  IBM report high annual revenue growth decade r...      5  Very Positive   \n",
       "1  career coach year quit 6 figure consulting job...      5  Very Positive   \n",
       "2  people make money Canva turn graphic design hu...      5  Very Positive   \n",
       "3  consumer business interest metaverse grow | ac...      5  Very Positive   \n",
       "4  plan internetâ€ ™ s transformation metaverse Web3      4       Positive   \n",
       "\n",
       "                                preprocessed_content  \n",
       "0  Jan 25 Reuters IBM Corp IBM. N on Wednesday re...  \n",
       "1  I spent seven years at ExxonMobil and two year...  \n",
       "2  After a tech startup fired 31yearold Shruti Pa...  \n",
       "3  Connect with gaming and metaverse leaders onli...  \n",
       "4  Check out all the ondemand sessions from the I...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908f70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveBaseScore(text):\n",
    "    if(text == \"Very Negative\"):\n",
    "        return 200\n",
    "    \n",
    "    elif(text == \"Negative\"):\n",
    "        return 100\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b2a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def process_csv(filename):  \n",
    "\n",
    "    with open ('assets/negative-words.txt', 'r', encoding='utf-8') as file:\n",
    "        negative_words_list = file.read().splitlines()\n",
    "\n",
    "    with open ('assets/bad-words.txt', 'r', encoding='utf-8') as file:\n",
    "        bad_words = file.read().splitlines()\n",
    "\n",
    "    with open ('assets/countries.txt', 'r', encoding='utf-8') as file:\n",
    "        countries = file.read().splitlines()\n",
    "\n",
    "    with open('assets/lawsuit.txt', 'r', encoding='utf-8') as file:\n",
    "        lawsuits = file.read().splitlines()\n",
    "\n",
    "    with open('assets/harassement.txt', 'r', encoding='utf-8') as file:\n",
    "        harassment = file.read().splitlines()\n",
    "\n",
    "\n",
    "\n",
    "# ========================#\n",
    "# Creating Final csv      #\n",
    "# ========================#\n",
    "    #definig charset\n",
    "    with open('COMMON-PROCESSED.csv', 'w', encoding='utf-8', newline='') as summary:\n",
    "        \n",
    "        # read first row from Uber.csv\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            df_new = pd.read_csv(filename)\n",
    "            df_new['preprocessed_content'] = df_new['content'].apply(preprocess)\n",
    "            try:\n",
    "                reader = csv.reader(file)\n",
    "                next(reader)\n",
    "\n",
    "                # write to csv\n",
    "                writer = csv.writer(summary)\n",
    "\n",
    "                # do for every news article\n",
    "                writer.writerows([[\"Index\", \"Source\", \"Author\", \"Title\", \"Description\", \"Content\", \"Headline Sentiment\", \"Offense Rating\", \"Negative Words\", \"Offensive Words\", \"Tags\"]])\n",
    "\n",
    "                for idx, row in enumerate(reader, start=1):\n",
    "                    raw_text = df_new['preprocessed_content'][idx]\n",
    "\n",
    "                    headline = df_new['title'][idx]\n",
    "                    headline_sentiment = df_new['sentiment'][idx]\n",
    "                    offense_rating = giveBaseScore(df_new['sentiment'][idx])\n",
    "\n",
    "                    negative_words=[]\n",
    "                    offensive_words=[]\n",
    "                    tags=[]\n",
    "\n",
    "                    # tag as negative\n",
    "\n",
    "                    nlp_text= nlp(raw_text)\n",
    "\n",
    "\n",
    "                    # add custom entities\n",
    "                    for word in nlp_text:\n",
    "                        # if it is a negative word\n",
    "                        if word.text.lower() in negative_words_list:\n",
    "                            offense_rating+=10\n",
    "                            negative_words.append(word.text)\n",
    "\n",
    "\n",
    "                        # if it is a highly offensive word \n",
    "                        if word.text.lower() in bad_words:\n",
    "                            offense_rating+=50\n",
    "                            offensive_words.append(word.text)\n",
    "\n",
    "\n",
    "                        # if the article is talks about lawsuits\n",
    "                        if word.text.lower() in lawsuits:\n",
    "                            offense_rating+=30\n",
    "                            tags.append(word.text)\n",
    "\n",
    "                        # if the article is about harassment\n",
    "                        if word.text.lower() in harassment:\n",
    "                            offense_rating+=50\n",
    "                            tags.append(word.text)\n",
    "\n",
    "                        # does article mention a country?\n",
    "                        if word.text.lower() in countries:\n",
    "                            tags.append(word.text)    \n",
    "\n",
    "                        # does article mention a person\n",
    "                        if word.ent_type_ == \"PERSON\":\n",
    "                            tags.append(word.text) \n",
    "                        \n",
    "                        if word.ent_type_ == \"ORG\":\n",
    "                            tags.append(word.text)\n",
    "                        \n",
    "                        if word.ent_type_ == \"GPE\":\n",
    "                            tags.append(word.text)\n",
    "\n",
    "\n",
    "                    if offense_rating>20:\n",
    "                        offense_rating-=10\n",
    "\n",
    "\n",
    "                    # Write each row\n",
    "                    writer.writerow(\n",
    "                        [\n",
    "                            idx,\n",
    "                            df_new['source'][idx],\n",
    "                            df_new['author'][idx],\n",
    "                            headline,\n",
    "                            df_new['description'][idx],\n",
    "                            df_new['content'][idx],\n",
    "                            headline_sentiment,\n",
    "                            offense_rating,\n",
    "                            list(set(negative_words)),\n",
    "                            list(set(offensive_words)),\n",
    "                            list(set(tags)),\n",
    "                        ]\n",
    "                    )\n",
    "                    print(f\"Article {idx} written to csv\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(e.__class__)\n",
    "                print(e.__doc__)\n",
    "                print(e.__traceback__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39dd8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1 written to csv\n",
      "Article 2 written to csv\n",
      "Article 3 written to csv\n",
      "Article 4 written to csv\n",
      "Article 5 written to csv\n",
      "Article 6 written to csv\n",
      "Article 7 written to csv\n",
      "Article 8 written to csv\n",
      "Article 9 written to csv\n",
      "Article 10 written to csv\n",
      "Article 11 written to csv\n",
      "Article 12 written to csv\n",
      "Article 13 written to csv\n",
      "Article 14 written to csv\n",
      "Article 15 written to csv\n",
      "Article 16 written to csv\n",
      "Article 17 written to csv\n",
      "Article 18 written to csv\n",
      "Article 19 written to csv\n",
      "Article 20 written to csv\n",
      "Article 21 written to csv\n",
      "Article 22 written to csv\n",
      "Article 23 written to csv\n",
      "Article 24 written to csv\n",
      "Article 25 written to csv\n",
      "Article 26 written to csv\n",
      "Article 27 written to csv\n",
      "Article 28 written to csv\n",
      "Article 29 written to csv\n",
      "Article 30 written to csv\n",
      "Article 31 written to csv\n",
      "Article 32 written to csv\n",
      "Article 33 written to csv\n",
      "Article 34 written to csv\n",
      "Article 35 written to csv\n",
      "Article 36 written to csv\n",
      "Article 37 written to csv\n",
      "Article 38 written to csv\n",
      "Article 39 written to csv\n",
      "Article 40 written to csv\n",
      "Article 41 written to csv\n",
      "Article 42 written to csv\n",
      "Article 43 written to csv\n",
      "Article 44 written to csv\n",
      "Article 45 written to csv\n",
      "Article 46 written to csv\n",
      "Article 47 written to csv\n",
      "Article 48 written to csv\n",
      "Article 49 written to csv\n",
      "Article 50 written to csv\n",
      "Article 51 written to csv\n",
      "Article 52 written to csv\n",
      "Article 53 written to csv\n",
      "Article 54 written to csv\n",
      "Article 55 written to csv\n",
      "Article 56 written to csv\n",
      "Article 57 written to csv\n",
      "Article 58 written to csv\n",
      "Article 59 written to csv\n",
      "Article 60 written to csv\n",
      "Article 61 written to csv\n",
      "Article 62 written to csv\n",
      "Article 63 written to csv\n",
      "Article 64 written to csv\n",
      "Article 65 written to csv\n",
      "Article 66 written to csv\n",
      "Article 67 written to csv\n",
      "Article 68 written to csv\n",
      "Article 69 written to csv\n",
      "Article 70 written to csv\n",
      "Article 71 written to csv\n",
      "Article 72 written to csv\n",
      "Article 73 written to csv\n",
      "Article 74 written to csv\n",
      "Article 75 written to csv\n",
      "Article 76 written to csv\n",
      "Article 77 written to csv\n",
      "Article 78 written to csv\n",
      "Article 79 written to csv\n",
      "Article 80 written to csv\n",
      "Article 81 written to csv\n",
      "Article 82 written to csv\n",
      "Article 83 written to csv\n",
      "Article 84 written to csv\n",
      "Article 85 written to csv\n",
      "Article 86 written to csv\n",
      "Article 87 written to csv\n",
      "Article 88 written to csv\n",
      "Article 89 written to csv\n",
      "Article 90 written to csv\n",
      "Article 91 written to csv\n",
      "Article 92 written to csv\n",
      "Article 93 written to csv\n",
      "Article 94 written to csv\n",
      "Article 95 written to csv\n",
      "Article 96 written to csv\n",
      "Article 97 written to csv\n",
      "Article 98 written to csv\n",
      "99\n",
      "<class 'KeyError'>\n",
      "Mapping key not found.\n",
      "<traceback object at 0x000002AEFC244180>\n"
     ]
    }
   ],
   "source": [
    "process_csv('file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e80316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
